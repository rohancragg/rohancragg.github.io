{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 rohancragg's Personal Tech Docs \u00b6 This repository contains hopelessly hopeful drafts of blog articles and other bobbins and gubbins I want to make sure I don't forget. One day I'll maybe even host these at https://www.rohancragg.co.uk - stranger things have happened ;-) Created with MkDocs and Material theme by squidfunk","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#rohancraggs-personal-tech-docs","text":"This repository contains hopelessly hopeful drafts of blog articles and other bobbins and gubbins I want to make sure I don't forget. One day I'll maybe even host these at https://www.rohancragg.co.uk - stranger things have happened ;-) Created with MkDocs and Material theme by squidfunk","title":"rohancragg's Personal Tech Docs"},{"location":"about/","text":"About Me \u00b6 Home page - rohancragg.co.uk StackExchange Profile:","title":"About Me"},{"location":"about/#about-me","text":"Home page - rohancragg.co.uk StackExchange Profile:","title":"About Me"},{"location":"aks/create-tls-secret/","text":"How to Create a TLS Secret \u00b6 I followed the command-line method (the first method) explained in this article Creating Kubernetes Secrets Using TLS/SSL as an Example - i.e. rather than using the second (YAML file) method. In order to do this I needed two files in the correct format. There are multiple formats that certificate and associated key files can be in (they can even be combined into a single file). In order to create a Kubernetes TLS secret I needed to ascertain the right ones to use. I was provided with a .pks file and needed to work out how to generate the correct artifacts from it. All I knew from the above article was that I needed a .crt and a .key file and at first I wasn't sure what these were. What are we trying to achieve? \u00b6 I needed obtain a TLS certificate and create a TLS Secret object in Kubernetes so that an Ingress resource could refer to the Secret in order that the certificate presented by the NGINX Ingress would look like this when visiting the associated Service in a web browser: (i.e. the TLS/HTTPS certificate should include the CA chain.) Getting the right files \u00b6 To get an encrypted private key: openssl pkcs12 -in domain.pfx -nocerts -out domain.enc.key To get an un-encrypted private key file openssl rsa -in domain.enc.key -outform PEM -out domain.key Note: be sure to delete this file once uploaded to the cluster so that you don't have an un-encrypted secret on your local machine To get the certificate file openssl pkcs12 -in domain.pfx -nodes -nokeys -nomac -out domain.crt The domain.crt file looks like this In my case it contains the full CA chain and so, in my case, there are three certificates each enclosed in BEGIN CERTIFICATE and END CERTIFICATE delimiters: -----BEGIN CERTIFICATE----- # ############################################################### # ############################################################### -----END CERTIFICATE----- Creating the TLS Secret in Kubernetes \u00b6 Create Kubernetes TLS Secret: kubectl create secret tls tlscert --key=\"tls.key\" --cert=\"tls.crt\" Additional Notes \u00b6 How to validate a key \u00b6 This works for both encrypted or un-encrypted keys : openssl rsa -check -in domain.enc.key or openssl rsa -check -in domain.key You should see the message 'RSA key ok': $ openssl rsa -check -in domain.enc.key Enter pass phrase for domain.enc.pem: RSA key ok writing RSA key -----BEGIN RSA PRIVATE KEY----- # ############################################################### # ############################################################### Where did my PKS file come from? \u00b6 I was provided with a .pks ( PKCS#12 ) file which had been created with the following command openssl pkcs12 -export -out domain.pfx -inkey domain.rsa -in domain.cer -certfile CAbundle.txt Where: domain.cer is the client certificate (i.e. without the Certification Authority (CA) chain ) domain.rsa is an un-encrypted version of the private key CAbundle.txt contains the CA certificates to append to create the CA chain domain.cer looks like this As you can see if contains just a single certificate domain.rsa looks like this How to get the client certificate (without the full CA chain) \u00b6 openssl pkcs12 -in domain.pfx -clcerts -nokeys -out domain.cer Some of the steps in this article are based on How to convert a PFX to a seperate .key/.crt file - by Mark Brilman I also referred to the OpenSSL PKCS12 man pages And to OpenSSL Essentials: Working with SSL Certificates, Private Keys and CSRs Updates \u00b6 While following an MS Learn module I found this article on using Azure Key Vault to do much of the above: Manage certificates \"...you can connect your Key Vault with a trusted certificate issuer (referred to as an integrated CA) and create the certificate directly in Azure Key Vault. You can then request to create a certificate and the Key Vault will interact directly with the CA to fulfill the request\" Alternatively, you can also just use Key Vault to create self-signed certificates for testing, or to create an X.509 certificate signing request (CSR) to pass on to the certificate authority (CA) to process and then later request Key Vault to merge the resulting X.509 certificate with the key pair held in Key Vault.","title":"Create a TLS Secret"},{"location":"aks/create-tls-secret/#how-to-create-a-tls-secret","text":"I followed the command-line method (the first method) explained in this article Creating Kubernetes Secrets Using TLS/SSL as an Example - i.e. rather than using the second (YAML file) method. In order to do this I needed two files in the correct format. There are multiple formats that certificate and associated key files can be in (they can even be combined into a single file). In order to create a Kubernetes TLS secret I needed to ascertain the right ones to use. I was provided with a .pks file and needed to work out how to generate the correct artifacts from it. All I knew from the above article was that I needed a .crt and a .key file and at first I wasn't sure what these were.","title":"How to Create a TLS Secret"},{"location":"aks/create-tls-secret/#what-are-we-trying-to-achieve","text":"I needed obtain a TLS certificate and create a TLS Secret object in Kubernetes so that an Ingress resource could refer to the Secret in order that the certificate presented by the NGINX Ingress would look like this when visiting the associated Service in a web browser: (i.e. the TLS/HTTPS certificate should include the CA chain.)","title":"What are we trying to achieve?"},{"location":"aks/create-tls-secret/#getting-the-right-files","text":"To get an encrypted private key: openssl pkcs12 -in domain.pfx -nocerts -out domain.enc.key To get an un-encrypted private key file openssl rsa -in domain.enc.key -outform PEM -out domain.key Note: be sure to delete this file once uploaded to the cluster so that you don't have an un-encrypted secret on your local machine To get the certificate file openssl pkcs12 -in domain.pfx -nodes -nokeys -nomac -out domain.crt The domain.crt file looks like this In my case it contains the full CA chain and so, in my case, there are three certificates each enclosed in BEGIN CERTIFICATE and END CERTIFICATE delimiters: -----BEGIN CERTIFICATE----- # ############################################################### # ############################################################### -----END CERTIFICATE-----","title":"Getting the right files"},{"location":"aks/create-tls-secret/#creating-the-tls-secret-in-kubernetes","text":"Create Kubernetes TLS Secret: kubectl create secret tls tlscert --key=\"tls.key\" --cert=\"tls.crt\"","title":"Creating the TLS Secret in Kubernetes"},{"location":"aks/create-tls-secret/#additional-notes","text":"","title":"Additional Notes"},{"location":"aks/create-tls-secret/#how-to-validate-a-key","text":"This works for both encrypted or un-encrypted keys : openssl rsa -check -in domain.enc.key or openssl rsa -check -in domain.key You should see the message 'RSA key ok': $ openssl rsa -check -in domain.enc.key Enter pass phrase for domain.enc.pem: RSA key ok writing RSA key -----BEGIN RSA PRIVATE KEY----- # ############################################################### # ###############################################################","title":"How to validate a key"},{"location":"aks/create-tls-secret/#where-did-my-pks-file-come-from","text":"I was provided with a .pks ( PKCS#12 ) file which had been created with the following command openssl pkcs12 -export -out domain.pfx -inkey domain.rsa -in domain.cer -certfile CAbundle.txt Where: domain.cer is the client certificate (i.e. without the Certification Authority (CA) chain ) domain.rsa is an un-encrypted version of the private key CAbundle.txt contains the CA certificates to append to create the CA chain domain.cer looks like this As you can see if contains just a single certificate domain.rsa looks like this","title":"Where did my PKS file come from?"},{"location":"aks/create-tls-secret/#how-to-get-the-client-certificate-without-the-full-ca-chain","text":"openssl pkcs12 -in domain.pfx -clcerts -nokeys -out domain.cer Some of the steps in this article are based on How to convert a PFX to a seperate .key/.crt file - by Mark Brilman I also referred to the OpenSSL PKCS12 man pages And to OpenSSL Essentials: Working with SSL Certificates, Private Keys and CSRs","title":"How to get the client certificate (without the full CA chain)"},{"location":"aks/create-tls-secret/#updates","text":"While following an MS Learn module I found this article on using Azure Key Vault to do much of the above: Manage certificates \"...you can connect your Key Vault with a trusted certificate issuer (referred to as an integrated CA) and create the certificate directly in Azure Key Vault. You can then request to create a certificate and the Key Vault will interact directly with the CA to fulfill the request\" Alternatively, you can also just use Key Vault to create self-signed certificates for testing, or to create an X.509 certificate signing request (CSR) to pass on to the certificate authority (CA) to process and then later request Key Vault to merge the resulting X.509 certificate with the key pair held in Key Vault.","title":"Updates"},{"location":"aks/domains/","text":"Clusters of Domains - designing domains and DNS for AKS \u00b6 While the [documentation on Azure DNS ] (https://docs.microsoft.com/en-us/azure/dns/) (at the time of writing in early 2020)) covers the essentials of what you need to know I personally found it somewhat dry in that it assumed that you knew what you wanted to do with Zones and records and mostly explained how to do it. I was finding it initially difficult synthesise and apply the pieces of information and there was a lack of something to place it all into a real-world solution-design context. Initially I felt like I was going round in circles simply trying to get a design to occur to me by simply reading the documentation. The break-through came when starting to implement something (I simply didnt know where I was going before I set off - no compass, no map). I registered a cheap domain I could use for testing for sake of this article I'll use the name contosoapps.xyz ). For example, how should I use Zones and records in combination with Kubernetes Ingress Controllers and Resources to expose a suite of web applications or microservices and their APIs to the public internet whilst supporting a 'route to live' set of environments into which to deploy these artefacts so that they can be tested while they are under development. In other words how can I efficiently use domain names to support Develeopment, Testing, and Staging Environments? Do I need a separate domain name for each Environment? Do I need to have a separate Kubernetes cluster for each or can I combine domain names and one or more clusters in any combination? I hope to answer the above questions. Note While my original design conundrum arose in how to use a domain name with one or more AKS clusters, this article will contain information relavant to using domain names with Azure Resources generally If at first you don't succeed - Play! \u00b6 The journey began while I was trying to grok the external-dns project. This is can be installed into a cluster and it watches deployments for any that require DNS records to be created or updated and it manages records in an associated Azure DNS Zone resource. Since I didn't have a custom domain name I could use I attempted to use the Azure-assigned fully qualified domain name (FQDN). Any AKS cluster into which a Service of type LoadBalancer has been deployed will have a Public IP resource deployed into the cluster-managed Resource Group. Any Azure Public IP (PIP) resource can optionally have a DNS name label applied which will then mean that this address will resolve to the IP address. Info The documentation states it best: \"You can specify a DNS domain name label for a public IP resource, which creates a mapping for domainnamelabel.location.cloudapp.azure.com to the public IP address in the Azure-managed DNS servers\" \\ from: IP address types and allocation methods in Azure > DNS hostname resolution So, in my case, given that adding a name label of contosoapps to my PIP I wondered if I could use external-dns to manage records for Ingess resources in my cluster, where the FQDN is therefore contosoapps.westeurope.cloudapp.azure.com . The Microsoft documentation covering externals-dns only applies to a cluster where the HTTP application routing add-on has been enabled and given that this add-on is not recommended for production use I wanted to avoiding this add-on. Info The HTTP application routing add-on automatically creates a DNS Zone for you and creates two controllers inside the cluster (an Ingress controller and External-DNS controller) and I wanted to understand how to deploy and manage these components properly without it happening 'auto-magically'! Eventually I was able to piece together the elements of a solution from this page (albeit not using Rancher in my case). Once this was working I was able to host multiple services, each with an Ingress based on the FQDN. So, for example, the demo-nginx app could be reached with the URL demo-nqinx.contosoapps.westeurope.cloudapp.azure.com . Application Name FQDN demo-nginx demo-nqinx.contosoapps.westeurope.cloudapp.azure.com demo-aspdotnet demo-aspdotnet.contosoapps.westeurope.cloudapp.azure.com But what if I also want to support multiple deployment environments? Application Name Environment URL demo-nginx Development demo-nqinx. dev .contosoapps.westeurope.cloudapp.azure.com * demo-nginx Staging demo-nqinx. test .contosoapps.westeurope.cloudapp.azure.com * demo-nginx Production demo-nqinx .contosoapps.westeurope.cloudapp.azure.com Unfortunately those URLs marked with * indicate that we cannot do this. Possible variations of the above that I considered were: demo-nqinx. dev ... dev .demo-nqinx... dev -demo-nqinx... I could not find this documented anywhere but it seems that name labels on Public IP Addresses only support a single label and so we cannot use FQDNS with aything other than 6-part names. In the first two examples above I'm trying to use 7-part names and in the third example I would need more than one name label on the IP address - one for each environment. Note In Progress - the plan is to flesh this out a bit more: https://jwendl.net/code-notes/azure/network/","title":"Clusters and Domains"},{"location":"aks/domains/#clusters-of-domains-designing-domains-and-dns-for-aks","text":"While the [documentation on Azure DNS ] (https://docs.microsoft.com/en-us/azure/dns/) (at the time of writing in early 2020)) covers the essentials of what you need to know I personally found it somewhat dry in that it assumed that you knew what you wanted to do with Zones and records and mostly explained how to do it. I was finding it initially difficult synthesise and apply the pieces of information and there was a lack of something to place it all into a real-world solution-design context. Initially I felt like I was going round in circles simply trying to get a design to occur to me by simply reading the documentation. The break-through came when starting to implement something (I simply didnt know where I was going before I set off - no compass, no map). I registered a cheap domain I could use for testing for sake of this article I'll use the name contosoapps.xyz ). For example, how should I use Zones and records in combination with Kubernetes Ingress Controllers and Resources to expose a suite of web applications or microservices and their APIs to the public internet whilst supporting a 'route to live' set of environments into which to deploy these artefacts so that they can be tested while they are under development. In other words how can I efficiently use domain names to support Develeopment, Testing, and Staging Environments? Do I need a separate domain name for each Environment? Do I need to have a separate Kubernetes cluster for each or can I combine domain names and one or more clusters in any combination? I hope to answer the above questions. Note While my original design conundrum arose in how to use a domain name with one or more AKS clusters, this article will contain information relavant to using domain names with Azure Resources generally","title":"Clusters of Domains - designing domains and DNS for AKS"},{"location":"aks/domains/#if-at-first-you-dont-succeed-play","text":"The journey began while I was trying to grok the external-dns project. This is can be installed into a cluster and it watches deployments for any that require DNS records to be created or updated and it manages records in an associated Azure DNS Zone resource. Since I didn't have a custom domain name I could use I attempted to use the Azure-assigned fully qualified domain name (FQDN). Any AKS cluster into which a Service of type LoadBalancer has been deployed will have a Public IP resource deployed into the cluster-managed Resource Group. Any Azure Public IP (PIP) resource can optionally have a DNS name label applied which will then mean that this address will resolve to the IP address. Info The documentation states it best: \"You can specify a DNS domain name label for a public IP resource, which creates a mapping for domainnamelabel.location.cloudapp.azure.com to the public IP address in the Azure-managed DNS servers\" \\ from: IP address types and allocation methods in Azure > DNS hostname resolution So, in my case, given that adding a name label of contosoapps to my PIP I wondered if I could use external-dns to manage records for Ingess resources in my cluster, where the FQDN is therefore contosoapps.westeurope.cloudapp.azure.com . The Microsoft documentation covering externals-dns only applies to a cluster where the HTTP application routing add-on has been enabled and given that this add-on is not recommended for production use I wanted to avoiding this add-on. Info The HTTP application routing add-on automatically creates a DNS Zone for you and creates two controllers inside the cluster (an Ingress controller and External-DNS controller) and I wanted to understand how to deploy and manage these components properly without it happening 'auto-magically'! Eventually I was able to piece together the elements of a solution from this page (albeit not using Rancher in my case). Once this was working I was able to host multiple services, each with an Ingress based on the FQDN. So, for example, the demo-nginx app could be reached with the URL demo-nqinx.contosoapps.westeurope.cloudapp.azure.com . Application Name FQDN demo-nginx demo-nqinx.contosoapps.westeurope.cloudapp.azure.com demo-aspdotnet demo-aspdotnet.contosoapps.westeurope.cloudapp.azure.com But what if I also want to support multiple deployment environments? Application Name Environment URL demo-nginx Development demo-nqinx. dev .contosoapps.westeurope.cloudapp.azure.com * demo-nginx Staging demo-nqinx. test .contosoapps.westeurope.cloudapp.azure.com * demo-nginx Production demo-nqinx .contosoapps.westeurope.cloudapp.azure.com Unfortunately those URLs marked with * indicate that we cannot do this. Possible variations of the above that I considered were: demo-nqinx. dev ... dev .demo-nqinx... dev -demo-nqinx... I could not find this documented anywhere but it seems that name labels on Public IP Addresses only support a single label and so we cannot use FQDNS with aything other than 6-part names. In the first two examples above I'm trying to use 7-part names and in the third example I would need more than one name label on the IP address - one for each environment. Note In Progress - the plan is to flesh this out a bit more: https://jwendl.net/code-notes/azure/network/","title":"If at first you don't succeed - Play!"},{"location":"misc/misc/","text":"Miscellanous Notes \u00b6 Windows Subsystem for Linux (WSL) environment \u00b6 Install: https://docs.microsoft.com/en-us/windows/wsl/install-win10 I found some really handy notes here: https://jwendl.net/code-notes/wsl/install/ As always, Scott Hanselman has the low-down to end all low-downs: Cool tips & tricks for WSL Shiny Linux Dev Environment How to make a pretty prompt in Windows Terminal Info See my page on Scoop & Co. for how to quickly and easily install Delugia Nerd Font mentioned in Scott's pretty prompt post above","title":"Miscellanous Notes"},{"location":"misc/misc/#miscellanous-notes","text":"","title":"Miscellanous Notes"},{"location":"misc/misc/#windows-subsystem-for-linux-wsl-environment","text":"Install: https://docs.microsoft.com/en-us/windows/wsl/install-win10 I found some really handy notes here: https://jwendl.net/code-notes/wsl/install/ As always, Scott Hanselman has the low-down to end all low-downs: Cool tips & tricks for WSL Shiny Linux Dev Environment How to make a pretty prompt in Windows Terminal Info See my page on Scoop & Co. for how to quickly and easily install Delugia Nerd Font mentioned in Scott's pretty prompt post above","title":"Windows Subsystem for Linux (WSL) environment"},{"location":"misc/scoop/","text":"The 'Scoop' on my personal machine build \u00b6 This page describes how I'm current -ly using Scoop (and other Package Managers) to configure my system The Daddy... Scoop ! \u00b6 Get scoop.sh and check out the wiki for latest info - or see below for the TL;DR Scoop focuses on open-source, command-line developer tools\" but then those are the kinds of tools I'm using more and more... ...You're familiar with UNIX tools, and you wish there were more of them on Windows from: https://github.com/lukesampson/scoop/wiki/Chocolatey-Comparison Install Scoop and base set of tools \u00b6 Invoke-Expression ( New-Object System . Net . WebClient ). DownloadString ( 'https://get.scoop.sh' ) scoop install sudo sudo scoop install 7zip git - -global scoop install curl grep sed less touch nano scoop install coreutils scoop install nodejs Tip you can use the Unix tool ls after installing coreutils but you first need to remove the PowerShell alias already in place\\ i.e. add this to your Powershell $profile : Remove-Alias -Name ls Remove-Alias -Name cat Remove-Alias -Name mv Remove-Alias -Name ps Remove-Alias -Name pwd Remove-Alias -Name rm Buckets \u00b6 Then, I add additional Buckets . Buckets are collections of apps which are additional / optional to the main bucket scoop bucket add extras scoop bucket add versions scoop bucket add Sysinternals Then yet more handy tools I use: scoop install azure-cli dotnet-sdk go hugo helm pwsh # from extras bucket: scoop install vcredist2019 linqpad notepadplusplus paint . net windows-terminal Info Other useful (possibly useful?) buckets that I've not yet had a use for: nonportable - non-portable Applications that need to retain state between versions full list of known buckets Paths \u00b6 Referencing the path to an application installed by Scoop %UserProfile%/scoop/apps Note Those installed with the --global (and with the sudo command) will reside in the path %ProgramData%/scoop/apps For each version of an application the files will be in a directory with the version number, but Scoop creates a Shim for the current version in the path %UserProfile%\\scoop\\apps\\{AppName}\\current . For example: the path to Python ( python.exe ) will be either: %UserProfile%\\scoop\\apps\\python\\3.8.1\\python.exe or: %UserProfile%\\scoop\\apps\\python\\current\\python.exe For system tools you'll probably want to use the current shim to avoid those tools breaking between updates. Specifying Application Versions \u00b6 The versions bucket contains a way to obtain versions other than the latest version of an application. This is used in combination with scoop reset command to switch between versions of an app. Scoop creates a shim for each version and scoop reset switches the current shim between those versions. For example: Switching-Ruby-And-Python-Versions Common Pre-Requisites \u00b6 The following is a set of common pre-requisites for installing tools and utilitied (e.g. the pip package manager for python tools): Python and PIP \u00b6 scoop install python scoop install curl curl https : // bootstrap . pypa . io / get-pip . py -o get-pip . py python get-pip . py python -m pip install -U pip System Fonts \u00b6 Here's another place where Scoop comes to the rescue to avoid clunky download and installs for system fonts! Info note how sudo is being used to install the font as a global / system font - this obvisouly pops up a UAC prompt as it requires elevated provilege to install a system font... scoop bucket add nerd-fonts sudo scoop install Delugia-Nerd-Font-Complete Productivity Tools \u00b6 MkDocs \u00b6 MkDocs \"Project documentation with Markdown\" I use this for writing this site! : pip install mkdocs python .\\ scoop \\ apps \\ python \\ current \\ Tools \\ scripts \\ win_add2path . py Install the Custom Theme \u00b6 Using Material theme and dependencies for CodeHilite pip install mkdocs-material pip install pygments # for source code syntax highlighting","title":"Scoop & Co"},{"location":"misc/scoop/#the-scoop-on-my-personal-machine-build","text":"This page describes how I'm current -ly using Scoop (and other Package Managers) to configure my system","title":"The 'Scoop' on my personal machine build"},{"location":"misc/scoop/#the-daddy-scoop","text":"Get scoop.sh and check out the wiki for latest info - or see below for the TL;DR Scoop focuses on open-source, command-line developer tools\" but then those are the kinds of tools I'm using more and more... ...You're familiar with UNIX tools, and you wish there were more of them on Windows from: https://github.com/lukesampson/scoop/wiki/Chocolatey-Comparison","title":"The Daddy... Scoop!"},{"location":"misc/scoop/#install-scoop-and-base-set-of-tools","text":"Invoke-Expression ( New-Object System . Net . WebClient ). DownloadString ( 'https://get.scoop.sh' ) scoop install sudo sudo scoop install 7zip git - -global scoop install curl grep sed less touch nano scoop install coreutils scoop install nodejs Tip you can use the Unix tool ls after installing coreutils but you first need to remove the PowerShell alias already in place\\ i.e. add this to your Powershell $profile : Remove-Alias -Name ls Remove-Alias -Name cat Remove-Alias -Name mv Remove-Alias -Name ps Remove-Alias -Name pwd Remove-Alias -Name rm","title":"Install Scoop and base set of tools"},{"location":"misc/scoop/#buckets","text":"Then, I add additional Buckets . Buckets are collections of apps which are additional / optional to the main bucket scoop bucket add extras scoop bucket add versions scoop bucket add Sysinternals Then yet more handy tools I use: scoop install azure-cli dotnet-sdk go hugo helm pwsh # from extras bucket: scoop install vcredist2019 linqpad notepadplusplus paint . net windows-terminal Info Other useful (possibly useful?) buckets that I've not yet had a use for: nonportable - non-portable Applications that need to retain state between versions full list of known buckets","title":"Buckets"},{"location":"misc/scoop/#paths","text":"Referencing the path to an application installed by Scoop %UserProfile%/scoop/apps Note Those installed with the --global (and with the sudo command) will reside in the path %ProgramData%/scoop/apps For each version of an application the files will be in a directory with the version number, but Scoop creates a Shim for the current version in the path %UserProfile%\\scoop\\apps\\{AppName}\\current . For example: the path to Python ( python.exe ) will be either: %UserProfile%\\scoop\\apps\\python\\3.8.1\\python.exe or: %UserProfile%\\scoop\\apps\\python\\current\\python.exe For system tools you'll probably want to use the current shim to avoid those tools breaking between updates.","title":"Paths"},{"location":"misc/scoop/#specifying-application-versions","text":"The versions bucket contains a way to obtain versions other than the latest version of an application. This is used in combination with scoop reset command to switch between versions of an app. Scoop creates a shim for each version and scoop reset switches the current shim between those versions. For example: Switching-Ruby-And-Python-Versions","title":"Specifying Application Versions"},{"location":"misc/scoop/#common-pre-requisites","text":"The following is a set of common pre-requisites for installing tools and utilitied (e.g. the pip package manager for python tools):","title":"Common Pre-Requisites"},{"location":"misc/scoop/#python-and-pip","text":"scoop install python scoop install curl curl https : // bootstrap . pypa . io / get-pip . py -o get-pip . py python get-pip . py python -m pip install -U pip","title":"Python and PIP"},{"location":"misc/scoop/#system-fonts","text":"Here's another place where Scoop comes to the rescue to avoid clunky download and installs for system fonts! Info note how sudo is being used to install the font as a global / system font - this obvisouly pops up a UAC prompt as it requires elevated provilege to install a system font... scoop bucket add nerd-fonts sudo scoop install Delugia-Nerd-Font-Complete","title":"System Fonts"},{"location":"misc/scoop/#productivity-tools","text":"","title":"Productivity Tools"},{"location":"misc/scoop/#mkdocs","text":"MkDocs \"Project documentation with Markdown\" I use this for writing this site! : pip install mkdocs python .\\ scoop \\ apps \\ python \\ current \\ Tools \\ scripts \\ win_add2path . py","title":"MkDocs"},{"location":"misc/scoop/#install-the-custom-theme","text":"Using Material theme and dependencies for CodeHilite pip install mkdocs-material pip install pygments # for source code syntax highlighting","title":"Install the Custom Theme"}]}